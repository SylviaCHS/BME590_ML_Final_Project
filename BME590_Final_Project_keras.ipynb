{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an introduction to tensorflow, let's use tensorflow to classify MNIST numerals. However, we will not be using keras -- while keras simplifies constructing basic neural networks, it decreases flexibility that we may need in the future (e.g., when we try to model optical processes). I will try keep this introduction as simple as possible without including too many extra features that, while likely to be useful, may distract you from getting something running for the first time. Once we get the basics down, in the future we can revisit some of the helpful tools, such as graph visualization and tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_feature(folder, num):\n",
    "    filename = glob.glob(os.path.join(folder, '*'))\n",
    "    img_arr = np.zeros([len(filename), 100, 100, 3])\n",
    "    label = num * np.ones(len(filename), dtype=\"float32\")\n",
    "    for i, name in enumerate(filename):\n",
    "        img = Image.open(name)\n",
    "        img_arr[i, :, :, :] = np.asarray(img, dtype=\"uint8\")\n",
    "    return img_arr, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8076, 100, 100, 3)\n",
      "(8076,)\n",
      "Training data shape (7268, 100, 100, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tb_img_arr, tb_label = read_feature('./TB_Image', 1)\n",
    "non_tb_img_arr, non_tb_label = read_feature('./Non-TB_Image', 0)\n",
    "images = np.concatenate((tb_img_arr, non_tb_img_arr))\n",
    "labels = np.concatenate((tb_label, non_tb_label))\n",
    "\n",
    "print(np.shape(images))\n",
    "print(np.shape(labels))\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.1)\n",
    "\n",
    "X_train = X_train.astype(np.int)\n",
    "X_val = X_val.astype(np.int)\n",
    "y_train = y_train.astype(np.int)\n",
    "y_val = y_val.astype(np.int)\n",
    "\n",
    "# change into one-hot vector\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 2) \n",
    "y_val = tf.keras.utils.to_categorical(y_val, 2)\n",
    "\n",
    "# reshape dataset\n",
    "X_train = X_train.reshape(X_train.shape[0], 100, 100, 3)\n",
    "X_val = X_val.reshape(X_val.shape[0], 100, 100, 3)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Training data shape', X_train.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train[0].reshape(100, 100, 3), cmap=plt.cm.Greys);\n",
    "ax2.imshow(X_train[1].reshape(100, 100, 3), cmap=plt.cm.Greys);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(model, loss, val_loss):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs/{}'.format('model_name'))\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                     batch_size=64,\n",
    "                     epochs=50,  # Run thru all the data point in each epoch\n",
    "                     verbose=1,\n",
    "                     validation_data=(X_val, y_val),\n",
    "                     #callbacks=[tensorboard])\n",
    "                     callbacks=[early_stop, tensorboard])\n",
    "    #val_err.append(hist.history['val_mean_absolute_error'][-1]) # a dict\n",
    "    loss.append(hist.history['loss'][-1])\n",
    "    val_loss.append(hist.history['val_loss'][-1])\n",
    "    \n",
    "    \n",
    "    return loss, val_loss, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example CNN used in class\n",
    "def VGG_cifar100(activ):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=activ, input_shape=(100, 100, 3)),\n",
    "        tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(128, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.MaxPool2D(padding='same'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(256, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.Conv2D(256, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.MaxPool2D(padding='same'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.Conv2D(512, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "        tf.keras.layers.Conv2D(512, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.Conv2D(512, (3,3), padding='same', activation=activ),\n",
    "        tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(4096, activation=activ),\n",
    "        tf.keras.layers.Dense(4096, activation=activ),\n",
    "        tf.keras.layers.Dense(1000, activation=activ),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    param = model.count_params()\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.000001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "   \n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnnmodel(n, activ, param):\n",
    "    model = tf.keras.Sequential([])\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(100, 100, 3)))\n",
    "    for i in range(n):\n",
    "        model.add(tf.keras.layers.Dense(100, activation=activ))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "    # model.summary()\n",
    "    # model.count_params()\n",
    "    param.append(model.count_params())\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.000001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', 'mae'])\n",
    "    return model, param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 13, 13, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 63,659,322\n",
      "Trainable params: 63,659,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7268 samples, validate on 808 samples\n",
      "Epoch 1/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.6599 - acc: 0.6076 - val_loss: 0.6479 - val_acc: 0.5718\n",
      "Epoch 2/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.6044 - acc: 0.7025 - val_loss: 0.5896 - val_acc: 0.6968\n",
      "Epoch 3/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.5668 - acc: 0.7367 - val_loss: 0.5489 - val_acc: 0.7302\n",
      "Epoch 4/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.5183 - acc: 0.7931 - val_loss: 0.4977 - val_acc: 0.8181\n",
      "Epoch 5/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.4703 - acc: 0.8261 - val_loss: 0.4609 - val_acc: 0.8589\n",
      "Epoch 6/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.4149 - acc: 0.8664 - val_loss: 0.3979 - val_acc: 0.8824\n",
      "Epoch 7/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.3753 - acc: 0.8773 - val_loss: 0.3503 - val_acc: 0.9097\n",
      "Epoch 8/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.3259 - acc: 0.9045 - val_loss: 0.3048 - val_acc: 0.9059\n",
      "Epoch 9/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2839 - acc: 0.9232 - val_loss: 0.2838 - val_acc: 0.9282\n",
      "Epoch 10/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2553 - acc: 0.9300 - val_loss: 0.2464 - val_acc: 0.9220\n",
      "Epoch 11/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2335 - acc: 0.9353 - val_loss: 0.2219 - val_acc: 0.9319\n",
      "Epoch 12/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2172 - acc: 0.9389 - val_loss: 0.2168 - val_acc: 0.9356\n",
      "Epoch 13/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2019 - acc: 0.9419 - val_loss: 0.2060 - val_acc: 0.9196\n",
      "Epoch 14/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1981 - acc: 0.9393 - val_loss: 0.1903 - val_acc: 0.9431\n",
      "Epoch 15/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1869 - acc: 0.9439 - val_loss: 0.1910 - val_acc: 0.9455\n",
      "Epoch 16/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1779 - acc: 0.9479 - val_loss: 0.1744 - val_acc: 0.9455\n",
      "Epoch 17/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1776 - acc: 0.9455 - val_loss: 0.1698 - val_acc: 0.9480\n",
      "Epoch 18/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1690 - acc: 0.9490 - val_loss: 0.1787 - val_acc: 0.9319\n",
      "Epoch 19/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1642 - acc: 0.9507 - val_loss: 0.1622 - val_acc: 0.9505\n",
      "Epoch 20/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1620 - acc: 0.9512 - val_loss: 0.1758 - val_acc: 0.9517\n",
      "Epoch 21/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1572 - acc: 0.9535 - val_loss: 0.1708 - val_acc: 0.9381\n",
      "Epoch 22/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1555 - acc: 0.9539 - val_loss: 0.1553 - val_acc: 0.9567\n",
      "Epoch 23/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1497 - acc: 0.9547 - val_loss: 0.1624 - val_acc: 0.9530\n",
      "Epoch 24/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1587 - acc: 0.9490 - val_loss: 0.1952 - val_acc: 0.9245\n",
      "Epoch 25/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1666 - acc: 0.9491 - val_loss: 0.1522 - val_acc: 0.9554\n",
      "Epoch 26/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1465 - acc: 0.9545 - val_loss: 0.1495 - val_acc: 0.9542\n",
      "Epoch 27/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1471 - acc: 0.9564 - val_loss: 0.1559 - val_acc: 0.9480\n",
      "Epoch 28/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1468 - acc: 0.9546 - val_loss: 0.1708 - val_acc: 0.9530\n",
      "Epoch 29/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1397 - acc: 0.9580 - val_loss: 0.1759 - val_acc: 0.9505\n"
     ]
    }
   ],
   "source": [
    "loss1 = []\n",
    "val_loss1 =[]\n",
    "param1 = []\n",
    "activ = 'relu'\n",
    "model, param1 = VGG_cifar100(activ)\n",
    "loss1, val_loss1, hist1= train_data(model, loss1, val_loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 13, 13, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 63,659,322\n",
      "Trainable params: 63,659,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7268 samples, validate on 808 samples\n",
      "Epoch 1/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.6607 - acc: 0.6054 - val_loss: 0.6488 - val_acc: 0.5693\n",
      "Epoch 2/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.6026 - acc: 0.7195 - val_loss: 0.5706 - val_acc: 0.7488\n",
      "Epoch 3/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.5082 - acc: 0.8111 - val_loss: 0.4631 - val_acc: 0.8057\n",
      "Epoch 4/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.3909 - acc: 0.8641 - val_loss: 0.3636 - val_acc: 0.8738\n",
      "Epoch 5/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.3097 - acc: 0.8923 - val_loss: 0.3018 - val_acc: 0.9022\n",
      "Epoch 6/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2690 - acc: 0.9037 - val_loss: 0.2744 - val_acc: 0.9109\n",
      "Epoch 7/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2477 - acc: 0.9128 - val_loss: 0.2623 - val_acc: 0.9121\n",
      "Epoch 8/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2338 - acc: 0.9185 - val_loss: 0.2515 - val_acc: 0.9146\n",
      "Epoch 9/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2257 - acc: 0.9218 - val_loss: 0.2409 - val_acc: 0.9158\n",
      "Epoch 10/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2163 - acc: 0.9269 - val_loss: 0.2329 - val_acc: 0.9233\n",
      "Epoch 11/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2114 - acc: 0.9293 - val_loss: 0.2170 - val_acc: 0.9220\n",
      "Epoch 12/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.2020 - acc: 0.9319 - val_loss: 0.2114 - val_acc: 0.9245\n",
      "Epoch 13/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1990 - acc: 0.9349 - val_loss: 0.2096 - val_acc: 0.9319\n",
      "Epoch 14/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1970 - acc: 0.9355 - val_loss: 0.2074 - val_acc: 0.9332\n",
      "Epoch 15/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1928 - acc: 0.9381 - val_loss: 0.1996 - val_acc: 0.9332\n",
      "Epoch 16/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1886 - acc: 0.9388 - val_loss: 0.1990 - val_acc: 0.9369\n",
      "Epoch 17/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1876 - acc: 0.9381 - val_loss: 0.1945 - val_acc: 0.9282\n",
      "Epoch 18/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1836 - acc: 0.9424 - val_loss: 0.1906 - val_acc: 0.9369\n",
      "Epoch 19/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1800 - acc: 0.9424 - val_loss: 0.1901 - val_acc: 0.9319\n",
      "Epoch 20/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1790 - acc: 0.9426 - val_loss: 0.1894 - val_acc: 0.9369\n",
      "Epoch 21/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1787 - acc: 0.9436 - val_loss: 0.1881 - val_acc: 0.9369\n",
      "Epoch 22/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1754 - acc: 0.9414 - val_loss: 0.1864 - val_acc: 0.9406\n",
      "Epoch 23/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1729 - acc: 0.9439 - val_loss: 0.1921 - val_acc: 0.9431\n",
      "Epoch 24/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1726 - acc: 0.9436 - val_loss: 0.1824 - val_acc: 0.9406\n",
      "Epoch 25/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1691 - acc: 0.9452 - val_loss: 0.1818 - val_acc: 0.9443\n",
      "Epoch 26/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1662 - acc: 0.9469 - val_loss: 0.1814 - val_acc: 0.9295\n",
      "Epoch 27/50\n",
      "7268/7268 [==============================] - 9s 1ms/sample - loss: 0.1656 - acc: 0.9466 - val_loss: 0.1872 - val_acc: 0.9443\n"
     ]
    }
   ],
   "source": [
    "loss1 = []\n",
    "val_loss1 =[]\n",
    "param1 = []\n",
    "activ = 'tanh'\n",
    "model, param1 = VGG_cifar100(activ)\n",
    "\n",
    "loss1, val_loss1, hist1= train_data(model, loss1, val_loss1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7268 samples, validate on 808 samples\n",
      "Epoch 1/50\n",
      "7268/7268 [==============================] - 3s 408us/sample - loss: 0.7768 - acc: 0.4600 - mean_absolute_error: 0.5133 - val_loss: 0.6988 - val_acc: 0.4963 - val_mean_absolute_error: 0.5004\n",
      "Epoch 2/50\n",
      "7268/7268 [==============================] - 2s 272us/sample - loss: 0.6841 - acc: 0.5976 - mean_absolute_error: 0.4937 - val_loss: 0.6761 - val_acc: 0.6077 - val_mean_absolute_error: 0.4896\n",
      "Epoch 3/50\n",
      "7268/7268 [==============================] - 2s 275us/sample - loss: 0.6730 - acc: 0.6054 - mean_absolute_error: 0.4874 - val_loss: 0.6701 - val_acc: 0.5829 - val_mean_absolute_error: 0.4850\n",
      "Epoch 4/50\n",
      "7268/7268 [==============================] - 2s 276us/sample - loss: 0.6587 - acc: 0.6286 - mean_absolute_error: 0.4787 - val_loss: 0.6519 - val_acc: 0.6300 - val_mean_absolute_error: 0.4738\n",
      "Epoch 5/50\n",
      "7268/7268 [==============================] - 2s 280us/sample - loss: 0.6495 - acc: 0.6439 - mean_absolute_error: 0.4716 - val_loss: 0.6453 - val_acc: 0.6040 - val_mean_absolute_error: 0.4665\n",
      "Epoch 6/50\n",
      "7268/7268 [==============================] - 2s 274us/sample - loss: 0.6286 - acc: 0.6790 - mean_absolute_error: 0.4592 - val_loss: 0.6218 - val_acc: 0.6720 - val_mean_absolute_error: 0.4540\n",
      "Epoch 7/50\n",
      "7268/7268 [==============================] - 2s 276us/sample - loss: 0.6098 - acc: 0.7047 - mean_absolute_error: 0.4461 - val_loss: 0.6120 - val_acc: 0.6522 - val_mean_absolute_error: 0.4416\n",
      "Epoch 8/50\n",
      "7268/7268 [==============================] - 2s 275us/sample - loss: 0.5907 - acc: 0.7221 - mean_absolute_error: 0.4326 - val_loss: 0.5821 - val_acc: 0.7042 - val_mean_absolute_error: 0.4246\n",
      "Epoch 9/50\n",
      "7268/7268 [==============================] - 2s 298us/sample - loss: 0.5671 - acc: 0.7448 - mean_absolute_error: 0.4177 - val_loss: 0.5710 - val_acc: 0.7673 - val_mean_absolute_error: 0.4236\n",
      "Epoch 10/50\n",
      "7268/7268 [==============================] - 2s 295us/sample - loss: 0.5509 - acc: 0.7562 - mean_absolute_error: 0.4043 - val_loss: 0.5360 - val_acc: 0.7859 - val_mean_absolute_error: 0.4005\n",
      "Epoch 11/50\n",
      "7268/7268 [==============================] - 2s 343us/sample - loss: 0.5444 - acc: 0.7453 - mean_absolute_error: 0.3951 - val_loss: 0.5550 - val_acc: 0.7005 - val_mean_absolute_error: 0.3877\n",
      "Epoch 12/50\n",
      "7268/7268 [==============================] - 2s 335us/sample - loss: 0.5171 - acc: 0.7711 - mean_absolute_error: 0.3798 - val_loss: 0.5032 - val_acc: 0.8007 - val_mean_absolute_error: 0.3761\n",
      "Epoch 13/50\n",
      "7268/7268 [==============================] - 2s 319us/sample - loss: 0.4944 - acc: 0.7997 - mean_absolute_error: 0.3660 - val_loss: 0.4921 - val_acc: 0.7859 - val_mean_absolute_error: 0.3610\n",
      "Epoch 14/50\n",
      "7268/7268 [==============================] - 2s 327us/sample - loss: 0.4840 - acc: 0.8045 - mean_absolute_error: 0.3573 - val_loss: 0.4893 - val_acc: 0.7525 - val_mean_absolute_error: 0.3508\n",
      "Epoch 15/50\n",
      "7268/7268 [==============================] - 2s 277us/sample - loss: 0.4751 - acc: 0.8057 - mean_absolute_error: 0.3480 - val_loss: 0.4564 - val_acc: 0.8428 - val_mean_absolute_error: 0.3435\n",
      "Epoch 16/50\n",
      "7268/7268 [==============================] - 2s 275us/sample - loss: 0.4505 - acc: 0.8304 - mean_absolute_error: 0.3347 - val_loss: 0.4553 - val_acc: 0.7884 - val_mean_absolute_error: 0.3314\n",
      "Epoch 17/50\n",
      "7268/7268 [==============================] - 2s 274us/sample - loss: 0.4400 - acc: 0.8363 - mean_absolute_error: 0.3270 - val_loss: 0.4301 - val_acc: 0.8243 - val_mean_absolute_error: 0.3182\n",
      "Epoch 18/50\n",
      "7268/7268 [==============================] - 2s 276us/sample - loss: 0.4372 - acc: 0.8279 - mean_absolute_error: 0.3198 - val_loss: 0.5029 - val_acc: 0.7599 - val_mean_absolute_error: 0.3581\n",
      "Epoch 19/50\n",
      "7268/7268 [==============================] - 2s 273us/sample - loss: 0.4239 - acc: 0.8350 - mean_absolute_error: 0.3109 - val_loss: 0.4528 - val_acc: 0.7599 - val_mean_absolute_error: 0.3122\n",
      "Epoch 20/50\n",
      "7268/7268 [==============================] - 2s 281us/sample - loss: 0.4090 - acc: 0.8477 - mean_absolute_error: 0.3015 - val_loss: 0.3893 - val_acc: 0.8688 - val_mean_absolute_error: 0.2944\n",
      "Epoch 21/50\n",
      "7268/7268 [==============================] - 2s 274us/sample - loss: 0.4033 - acc: 0.8487 - mean_absolute_error: 0.2958 - val_loss: 0.3892 - val_acc: 0.8391 - val_mean_absolute_error: 0.2861\n",
      "Epoch 22/50\n",
      "7268/7268 [==============================] - 2s 273us/sample - loss: 0.4002 - acc: 0.8491 - mean_absolute_error: 0.2900 - val_loss: 0.3892 - val_acc: 0.8230 - val_mean_absolute_error: 0.2814\n",
      "Epoch 23/50\n",
      "7268/7268 [==============================] - 2s 273us/sample - loss: 0.3794 - acc: 0.8634 - mean_absolute_error: 0.2784 - val_loss: 0.3654 - val_acc: 0.8577 - val_mean_absolute_error: 0.2700\n",
      "Epoch 24/50\n",
      "7268/7268 [==============================] - 2s 276us/sample - loss: 0.3879 - acc: 0.8462 - mean_absolute_error: 0.2778 - val_loss: 0.3523 - val_acc: 0.8787 - val_mean_absolute_error: 0.2629\n",
      "Epoch 25/50\n",
      "7268/7268 [==============================] - 2s 274us/sample - loss: 0.3813 - acc: 0.8492 - mean_absolute_error: 0.2726 - val_loss: 0.3528 - val_acc: 0.8577 - val_mean_absolute_error: 0.2583\n",
      "Epoch 26/50\n",
      "7268/7268 [==============================] - 2s 273us/sample - loss: 0.3687 - acc: 0.8620 - mean_absolute_error: 0.2653 - val_loss: 0.3369 - val_acc: 0.8874 - val_mean_absolute_error: 0.2524\n",
      "Epoch 27/50\n",
      "7268/7268 [==============================] - 2s 277us/sample - loss: 0.3541 - acc: 0.8766 - mean_absolute_error: 0.2571 - val_loss: 0.3345 - val_acc: 0.8861 - val_mean_absolute_error: 0.2483\n",
      "Epoch 28/50\n",
      "7268/7268 [==============================] - 2s 275us/sample - loss: 0.3441 - acc: 0.8825 - mean_absolute_error: 0.2505 - val_loss: 0.3273 - val_acc: 0.9084 - val_mean_absolute_error: 0.2470\n",
      "Epoch 29/50\n",
      "7268/7268 [==============================] - 2s 276us/sample - loss: 0.3470 - acc: 0.8736 - mean_absolute_error: 0.2493 - val_loss: 0.3194 - val_acc: 0.8923 - val_mean_absolute_error: 0.2376\n",
      "Epoch 30/50\n",
      "7268/7268 [==============================] - 2s 276us/sample - loss: 0.3353 - acc: 0.8828 - mean_absolute_error: 0.2421 - val_loss: 0.3839 - val_acc: 0.8490 - val_mean_absolute_error: 0.2739\n",
      "Epoch 31/50\n",
      "7268/7268 [==============================] - 2s 275us/sample - loss: 0.3397 - acc: 0.8762 - mean_absolute_error: 0.2416 - val_loss: 0.3123 - val_acc: 0.8849 - val_mean_absolute_error: 0.2300\n",
      "Epoch 32/50\n",
      "7268/7268 [==============================] - 2s 276us/sample - loss: 0.3308 - acc: 0.8839 - mean_absolute_error: 0.2363 - val_loss: 0.3090 - val_acc: 0.8824 - val_mean_absolute_error: 0.2257\n",
      "Epoch 33/50\n",
      "7268/7268 [==============================] - 2s 276us/sample - loss: 0.3244 - acc: 0.8865 - mean_absolute_error: 0.2319 - val_loss: 0.3168 - val_acc: 0.8589 - val_mean_absolute_error: 0.2245\n",
      "Epoch 34/50\n",
      "7268/7268 [==============================] - 2s 274us/sample - loss: 0.3219 - acc: 0.8883 - mean_absolute_error: 0.2276 - val_loss: 0.2956 - val_acc: 0.9121 - val_mean_absolute_error: 0.2189\n",
      "Epoch 35/50\n",
      "7268/7268 [==============================] - 2s 277us/sample - loss: 0.3349 - acc: 0.8769 - mean_absolute_error: 0.2312 - val_loss: 0.3023 - val_acc: 0.8738 - val_mean_absolute_error: 0.2155\n",
      "Epoch 36/50\n",
      "7268/7268 [==============================] - 2s 275us/sample - loss: 0.3166 - acc: 0.8887 - mean_absolute_error: 0.2218 - val_loss: 0.3198 - val_acc: 0.9010 - val_mean_absolute_error: 0.2321\n",
      "Epoch 37/50\n",
      "7268/7268 [==============================] - 2s 277us/sample - loss: 0.3028 - acc: 0.8978 - mean_absolute_error: 0.2148 - val_loss: 0.2995 - val_acc: 0.8812 - val_mean_absolute_error: 0.2106\n"
     ]
    }
   ],
   "source": [
    "loss1 = []\n",
    "val_loss1 =[]\n",
    "param1 = []\n",
    "activ = 'relu'\n",
    "model, param1 = dnnmodel(15, activ, param1)\n",
    "loss1, val_loss1, hist1= train_data(model, loss1, val_loss1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "def resnet():\n",
    "    input_tensor = tf.keras.layers.Input(shape=(100, 100, 3))\n",
    "    model = ResNet50(include_top=True, weights=None, input_tensor=input_tensor, input_shape=None, pooling=None, classes=2)\n",
    "    param = model.count_params()\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.00001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100, 100, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 106, 106, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 50, 50, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalizationV1) (None, 50, 50, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 50, 50, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 52, 52, 64)   0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 25, 25, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 25, 25, 64)   4160        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 25, 25, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 25, 25, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 25, 25, 64)   36928       activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 25, 25, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 25, 25, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 25, 25, 256)  16640       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 25, 25, 256)  16640       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 25, 25, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 25, 25, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 25, 25, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 25, 25, 256)  0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 25, 25, 64)   16448       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 25, 25, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 25, 25, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 25, 25, 64)   36928       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 25, 25, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 25, 25, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 25, 25, 256)  16640       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 25, 25, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 25, 25, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 25, 25, 256)  0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 25, 25, 64)   16448       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 25, 25, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 25, 25, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 25, 25, 64)   36928       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 25, 25, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 25, 25, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 25, 25, 256)  16640       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 25, 25, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 25, 25, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 25, 25, 256)  0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 13, 13, 128)  32896       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 13, 13, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 13, 13, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 13, 13, 128)  147584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 13, 13, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 13, 13, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 13, 13, 512)  66048       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 13, 13, 512)  131584      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 13, 13, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 13, 13, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 13, 13, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 13, 13, 512)  0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 13, 13, 128)  65664       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 13, 13, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 13, 13, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 13, 13, 128)  147584      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 13, 13, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 13, 13, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 13, 13, 512)  66048       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 13, 13, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 13, 13, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 13, 13, 512)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 13, 13, 128)  65664       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 13, 13, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 13, 13, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 13, 13, 128)  147584      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 13, 13, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 13, 13, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 13, 13, 512)  66048       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 13, 13, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 13, 13, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 13, 13, 512)  0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 13, 13, 128)  65664       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 13, 13, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 13, 13, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 13, 13, 128)  147584      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 13, 13, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 13, 13, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 13, 13, 512)  66048       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 13, 13, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 13, 13, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 13, 13, 512)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 7, 7, 256)    131328      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 7, 7, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 7, 7, 256)    590080      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 7, 7, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 7, 7, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 7, 7, 1024)   263168      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 7, 7, 1024)   525312      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 7, 7, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 7, 7, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 7, 7, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 7, 7, 1024)   0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 7, 7, 256)    262400      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 7, 7, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 7, 7, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 7, 7, 256)    590080      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 7, 7, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 7, 7, 1024)   263168      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 7, 7, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 7, 7, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 1024)   0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 7, 7, 256)    262400      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 7, 7, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 7, 7, 256)    590080      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 7, 7, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 7, 7, 1024)   263168      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 7, 7, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 7, 7, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 1024)   0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 7, 7, 256)    262400      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 7, 7, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 7, 7, 256)    590080      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 7, 7, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 7, 7, 1024)   263168      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 7, 7, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 7, 7, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 1024)   0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 7, 7, 256)    262400      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 7, 7, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 7, 7, 256)    590080      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 7, 7, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 7, 7, 1024)   263168      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 7, 7, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 7, 7, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 1024)   0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 7, 7, 256)    262400      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 7, 7, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 7, 7, 256)    590080      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 7, 7, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 7, 7, 1024)   263168      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 7, 7, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 7, 7, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 1024)   0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 4, 4, 512)    524800      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 4, 4, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 4, 4, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 4, 4, 2048)   2099200     activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 4, 4, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 4, 4, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 4, 4, 2048)   0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 4, 4, 512)    1049088     activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 4, 4, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 4, 4, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 4, 4, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 4, 4, 2048)   0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 4, 4, 512)    1049088     activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 4, 4, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 4, 4, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 4, 4, 512)    2359808     activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 4, 4, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 4, 4, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 4, 4, 2048)   1050624     activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 4, 4, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 4, 4, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 4, 4, 2048)   0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 2)            4098        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "Train on 7268 samples, validate on 808 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7268/7268 [==============================] - 22s 3ms/sample - loss: 0.6956 - acc: 0.5557 - val_loss: 3.2630 - val_acc: 0.5656\n",
      "Epoch 2/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.6496 - acc: 0.6095 - val_loss: 0.7184 - val_acc: 0.6089\n",
      "Epoch 3/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.6306 - acc: 0.6379 - val_loss: 0.6427 - val_acc: 0.6250\n",
      "Epoch 4/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.6004 - acc: 0.6783 - val_loss: 0.6067 - val_acc: 0.6708\n",
      "Epoch 5/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.5615 - acc: 0.7133 - val_loss: 0.5849 - val_acc: 0.6918\n",
      "Epoch 6/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.5200 - acc: 0.7367 - val_loss: 0.5430 - val_acc: 0.7401\n",
      "Epoch 7/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.4868 - acc: 0.7577 - val_loss: 0.5114 - val_acc: 0.7587\n",
      "Epoch 8/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.4397 - acc: 0.7980 - val_loss: 0.4744 - val_acc: 0.7723\n",
      "Epoch 9/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.4047 - acc: 0.8182 - val_loss: 0.5008 - val_acc: 0.7797\n",
      "Epoch 10/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.3855 - acc: 0.8221 - val_loss: 0.4458 - val_acc: 0.8168\n",
      "Epoch 11/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.3505 - acc: 0.8473 - val_loss: 0.4353 - val_acc: 0.8193\n",
      "Epoch 12/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.3434 - acc: 0.8476 - val_loss: 0.4386 - val_acc: 0.8267\n",
      "Epoch 13/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.3160 - acc: 0.8636 - val_loss: 0.3970 - val_acc: 0.8304\n",
      "Epoch 14/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.3030 - acc: 0.8693 - val_loss: 0.4281 - val_acc: 0.8267\n",
      "Epoch 15/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.2959 - acc: 0.8697 - val_loss: 0.4337 - val_acc: 0.8193\n",
      "Epoch 16/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.2811 - acc: 0.8771 - val_loss: 0.3813 - val_acc: 0.8329\n",
      "Epoch 17/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.2600 - acc: 0.8930 - val_loss: 0.4352 - val_acc: 0.8453\n",
      "Epoch 18/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.2462 - acc: 0.8961 - val_loss: 0.4062 - val_acc: 0.8366\n",
      "Epoch 19/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.2444 - acc: 0.8987 - val_loss: 0.3429 - val_acc: 0.8676\n",
      "Epoch 20/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.2366 - acc: 0.9037 - val_loss: 0.3503 - val_acc: 0.8564\n",
      "Epoch 21/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.2217 - acc: 0.9111 - val_loss: 0.3481 - val_acc: 0.8552\n",
      "Epoch 22/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.2187 - acc: 0.9119 - val_loss: 0.3283 - val_acc: 0.8787\n",
      "Epoch 23/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.2051 - acc: 0.9172 - val_loss: 0.3462 - val_acc: 0.8750\n",
      "Epoch 24/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.1936 - acc: 0.9256 - val_loss: 0.3858 - val_acc: 0.8577\n",
      "Epoch 25/50\n",
      "7268/7268 [==============================] - 16s 2ms/sample - loss: 0.1907 - acc: 0.9229 - val_loss: 0.3503 - val_acc: 0.8626\n"
     ]
    }
   ],
   "source": [
    "loss1 = []\n",
    "val_loss1 =[]\n",
    "param1 = []\n",
    "model, param = resnet()\n",
    "loss1, val_loss1, hist1= train_data(model, loss1, val_loss1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simulating a microscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast as a float32:\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dataset into microscope samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavelength = .5\n",
    "thickness = 1 * wavelength\n",
    "\n",
    "def convert_dataset(X, wavelength, thickness):\n",
    "    X1 = X / np.max(X)\n",
    "    X2 = np.exp(1j * X1 * thickness / wavelength)\n",
    "    return X2\n",
    "\n",
    "X_train = convert_MNIST(X_train, wavelength, thickness)\n",
    "X_test = convert_MNIST(X_test, wavelength, thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create input pipeline for generating training/testing batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be either X_train/y_train or X_test/y_test, so we make a placeholder that we can feed into:\n",
    "X_train_or_test = tf.placeholder(tf.complex64, [None, 100, 100], name='input_image')\n",
    "y_train_or_test = tf.placeholder(tf.int32, [None], name='image_label')\n",
    "batch_size = 32\n",
    "\n",
    "# create a tf dataset, from which we can generate batches\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train_or_test, y_train_or_test))\n",
    "dataset = dataset.batch(batch_size).repeat(None)\n",
    "batch_generator = dataset.make_initializable_iterator()\n",
    "X_batch, y_batch = batch_generator.get_next()  # batches symbolically generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create complex-valued trainable illumination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this flag to allow/disallow training of the input illumination; tf.Variable has an argument called \"trainable\":\n",
    "train_illumination = True  \n",
    "\n",
    "# create the variable corresponding to the input illumination phase; initialize to a constant phase:\n",
    "# (remember this is a weight variable that you will optimize!)\n",
    "input_illumination_phase = tf.Variable(tf.random.uniform([100,100]),dtype=np.float32,trainable=train_illumination)\n",
    "input_illumination_phase = tf.cast(input_illumination_phase, tf.complex64)\n",
    "\n",
    "# using that input phase, create the input field:\n",
    "input_illumination = tf.exp(1j*input_illumination_phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate the emerging field from the sample and propagate the emerging field to the aperture plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure to match the shapes/dimensions to enable broadcasting:\n",
    "emerging_field = X_batch * input_illumination\n",
    "aperture_plane = tf.fft2d(emerging_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create complex-valued trainable aperture function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this flag to allow/disallow training of the aperture plane; pass this into the tf.Variable definition:\n",
    "train_aperture = True\n",
    "\n",
    "# the aperture function consists of two parts: 1) the circular aperture as in HW4, and 2) a trainable 28x28 phase array\n",
    "# create a circular aperture as you did in HW4:\n",
    "r = 0.25 * 100\n",
    "circ_aper = np.zeros([100,100])\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        if (i-50)**2+(j-50)**2 <= r**2:\n",
    "            circ_aper[i,j] = 1\n",
    "\n",
    "plt.imshow(circ_aper)\n",
    "circ_aper = np.fft.fftshift(circ_aper)\n",
    "\n",
    "# create the variable corresponding to the aperture phase; initialize to a constant phase:\n",
    "# (remember this is a weight variable that you will optimize!)\n",
    "aperture_phase = tf.Variable(tf.random.uniform([100,100]),dtype=np.float32)\n",
    "aperture_phase = tf.cast(aperture_phase, tf.complex64)\n",
    "\n",
    "# write the full aperture function, combining the above two components:\n",
    "aperture = circ_aper * tf.exp(1j * aperture_phase)\n",
    "\n",
    "# filter the field that you propagated:\n",
    "aperture_plane_filtered = aperture_plane * aperture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### propagate to the image plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# propagate the field from the aperture plane to the image plane and convert it to intensity:\n",
    "image = (tf.abs(tf.ifft2d(aperture_plane_filtered)))**2\n",
    "#image = tf.abs(tf_fftshift2(tf.fft2d(tf_ifftshift2(aperture_plane_filtered))))**2\n",
    "\n",
    "# add noise:\n",
    "#image += tf.random_normal([100,100],stddev=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
